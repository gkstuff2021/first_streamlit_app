
-- setup
--check warehouse
select current_region();

create database util_db;

use role accountadmin;

create or replace api integration dora_api_integration
api_provider = aws_api_gateway
api_aws_role_arn = 'arn:aws:iam::321463406630:role/snowflakeLearnerAssumedRole'
enabled = true
api_allowed_prefixes = ('https://awy6hshxy4.execute-api.us-west-2.amazonaws.com/dev/edu_dora');

create or replace external function util_db.public.grader(        
 step varchar     
 , passed boolean     
 , actual integer     
 , expected integer    
 , description varchar) 
 returns variant 
 api_integration = dora_api_integration 
 context_headers = (current_timestamp,current_account, current_statement) 
 as 'https://awy6hshxy4.execute-api.us-west-2.amazonaws.com/dev/edu_dora/grader'  
;  
create or replace external function util_db.public.greeting(
      email varchar
    , firstname varchar
    , middlename varchar
    , lastname varchar)
returns variant
api_integration = dora_api_integration
context_headers = (current_timestamp,current_account, current_statement) 
as 'https://awy6hshxy4.execute-api.us-west-2.amazonaws.com/dev/edu_dora/greeting'
;

select util_db.public.greeting('gopalwun@gmail.com', 'gopal', 'v', 'wunnava');

select util_db.public.grader(step, (actual = expected), actual, expected, description) as graded_results from
(SELECT 
 'DORA_IS_WORKING' as step
 ,(select 123 ) as actual
 ,123 as expected
 ,'Dora is working!' as description
); 



select current_account();

--DW47757



create database AGS_GAME_AUDIENCE;

drop schema AGS_GAME_AUDIENCE.public;

create schema AGS_GAME_AUDIENCE.raw;

create table AGS_GAME_AUDIENCE.raw.GAME_LOGS(
   RAW_LOG VARIANT
    -- , <col2_name> <col2_type>
    -- supported types: https://docs.snowflake.com/en/sql-reference/intro-summary-data-types.html
    );
    -- comment = '<comment>';

CREATE STAGE uni_kishore
url = 's3://uni-kishore';

list @uni_kishore/kickoff;

CREATE OR REPLACE FILE FORMAT AGS_GAME_AUDIENCE.RAW.FF_JSON_LOGS
  TYPE = 'JSON'
  COMPRESSION = 'AUTO' 
  strip_outer_array = true
  TRIM_SPACE = FALSE 
  DATE_FORMAT = 'AUTO' 
  TIMESTAMP_FORMAT = 'AUTO' 
  NULL_IF = ('\\N');


SELECT $1
FROM @uni_kishore/kickoff
(file_format => FF_JSON_LOGS);

COPY INTO AGS_GAME_AUDIENCE.raw.GAME_LOGS
FROM @uni_kishore/kickoff
file_format = (FORMAT_NAME = FF_JSON_LOGS);


select 
RAW_LOG:agent::text as AGENT, 
RAW_LOG:user_login::text as USER_LOGIN, 
RAW_LOG:user_event::text as USER_EVENT, 
RAW_LOG:datetime_iso8601::TIMESTAMP_NTZ as datetime_iso8601,
RAW_LOG
from GAME_LOGS;

select 
RAW_LOG:agent::text as AGENT, 
RAW_LOG:user_login::text as USER_LOGIN, 
RAW_LOG:user_event::text as USER_EVENT, 
RAW_LOG:datetime_iso8601::TIMESTAMP_NTZ as datetime_iso8601,
RAW_LOG:datetime_iso8601::TIMESTAMP_LTZ as datetime_iso8601_LTC,
RAW_LOG:datetime_iso8601::TIMESTAMP_TZ as datetime_iso8601_TZ,
RAW_LOG
from GAME_LOGS;

select count(*) from GAME_LOGS;
select * from logs;


create or replace view AGS_GAME_AUDIENCE.raw.logs
as
select 
--RAW_LOG:agent::text as AGENT, 
RAW_LOG:user_login::text as USER_LOGIN, 
RAW_LOG:user_event::text as USER_EVENT, 
RAW_LOG:ip_address::text as IP_ADDRESS, 
RAW_LOG:datetime_iso8601::TIMESTAMP_NTZ as datetime_iso8601,
RAW_LOG

from GAME_LOGS;

select * from AGS_GAME_AUDIENCE.raw.logs;


-- DO NOT EDIT THIS CODE
select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
 SELECT
 'DNGW01' as step
  ,(
      select count(*)  
      from ags_game_audience.raw.logs
      where is_timestamp_ntz(to_variant(datetime_iso8601))= TRUE 
   ) as actual
, 250 as expected
, 'Project DB and Log File Set Up Correctly' as description
); 

SELECT current_timestamp()::TIMESTAMP_LTZ ,current_timestamp()::TIMESTAMP_NTZ,current_timestamp()::TIMESTAMP_TZ;

--what time zone is your account(and/or session) currently set to? Is it -0700?
select current_timestamp();

--worksheets are sometimes called sessions -- we'll be changing the worksheet time zone
alter session set timezone = 'UTC';
select current_timestamp();

--how did the time differ after changing the time zone for the worksheet?
alter session set timezone = 'Africa/Nairobi';
select current_timestamp();

alter session set timezone = 'Pacific/Funafuti';
select current_timestamp();

alter session set timezone = 'Asia/Shanghai';
select current_timestamp();

--show the account parameter called timezone
show parameters like 'timezone';

alter session set timezone = 'EST';
select current_timestamp();


list @uni_kishore;

--s3://uni-kishore/updated_feed/DNGW_updated_feed_0_0_0.json



SELECT $1
FROM @uni_kishore/updated_feed
(file_format => FF_JSON_LOGS);


COPY INTO AGS_GAME_AUDIENCE.raw.GAME_LOGS
FROM @uni_kishore/updated_feed
file_format = (FORMAT_NAME = FF_JSON_LOGS);


select 
$1:agent::text,
$1:ip_address::text
from AGS_GAME_AUDIENCE.raw.GAME_LOGS;


--looking for empty AGENT column
select * 
from ags_game_audience.raw.LOGS
where agent is null;

--looking for non-empty IP_ADDRESS column
select 
RAW_LOG:ip_address::text as IP_ADDRESS
,*
from ags_game_audience.raw.LOGS
where RAW_LOG:ip_address::text is not null;


sELECT * FROM LOGs WHERE USER_LOGIN ilike '%Praj%';

select (count(*) * -1) as tally
        from ags_game_audience.raw.logs ;


        select count(*) as tally
        from ags_game_audience.raw.game_logs ;


create or replace view AGS_GAME_AUDIENCE.raw.logs
as
select 
--RAW_LOG:agent::text as AGENT, 
RAW_LOG:user_login::text as USER_LOGIN, 
RAW_LOG:user_event::text as USER_EVENT, 
RAW_LOG:ip_address::text as IP_ADDRESS, 
RAW_LOG:datetime_iso8601::TIMESTAMP_NTZ as datetime_iso8601,
RAW_LOG
from GAME_LOGS
where RAW_LOG:ip_address::text is not null;


        

select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
SELECT
   'DNGW02' as step
   ,( select sum(tally) from(
        select (count(*) * -1) as tally
        from ags_game_audience.raw.logs 
        union all
        select count(*) as tally
        from ags_game_audience.raw.game_logs)     
     ) as actual
   ,250 as expected
   ,'View is filtered' as description
); 


select * from AGS_GAME_AUDIENCE.raw.logs;

select parse_ip('184.105.65.130','inet');


select parse_ip('107.217.231.17','inet'):host;


select parse_ip('107.217.231.17','inet'):family;



create schema AGS_GAME_AUDIENCE.ENHANCED;


--Look up Kishore and Prajina's Time Zone in the IPInfo share using his headset's IP Address with the PARSE_IP function.
select start_ip, end_ip, start_ip_int, end_ip_int, city, region, country, timezone
from IPINFO_GEOLOC.demo.location
where parse_ip('100.41.16.160', 'inet'):ipv4 --Kishore's Headset's IP Address
BETWEEN start_ip_int AND end_ip_int;

--ALTER SESSION SET USE_CACHED_RESULT = FALSE;
ALTER SESSION SET USE_CACHED_RESULT = TRUE;

--Join the log and location tables to add time zone to each row using the PARSE_IP function.
select logs.*
       , loc.city
       , loc.region
       , loc.country
       , loc.timezone
from AGS_GAME_AUDIENCE.RAW.LOGS logs
join IPINFO_GEOLOC.demo.location loc
where parse_ip(logs.ip_address, 'inet'):ipv4 
BETWEEN start_ip_int AND end_ip_int;


--Use two functions supplied by IPShare to help with an efficient IP Lookup Process!
SELECT logs.ip_address
, logs.user_login
, logs.user_event
, logs.datetime_iso8601
, city
, region
, country
, timezone 
,CONVERT_TIMEZONE('UTC',logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME("GAME_EVENT_LTZ") AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int;


--a Look Up table to convert from hour number to "time of day name"
create or replace table ags_game_audience.raw.time_of_day_lu
(  hour number
   ,tod_name varchar(25)
);

--insert statement to add all 24 rows to the table
insert into ags_game_audience.raw.time_of_day_lu
values
(6,'Early morning'),
(7,'Early morning'),
(8,'Early morning'),
(9,'Mid-morning'),
(10,'Mid-morning'),
(11,'Late morning'),
(12,'Late morning'),
(13,'Early afternoon'),
(14,'Early afternoon'),
(15,'Mid-afternoon'),
(16,'Mid-afternoon'),
(17,'Late afternoon'),
(18,'Late afternoon'),
(19,'Early evening'),
(20,'Early evening'),
(21,'Late evening'),
(22,'Late evening'),
(23,'Late evening'),
(0,'Late at night'),
(1,'Late at night'),
(2,'Late at night'),
(3,'Toward morning'),
(4,'Toward morning'),
(5,'Toward morning');



--Check your table to see if you loaded it properly
select tod_name, listagg(hour,',') 
from ags_game_audience.raw.time_of_day_lu
group by tod_name;


--modified sql

--Use two functions supplied by IPShare to help with an efficient IP Lookup Process!
--wrong query below
SELECT logs.ip_address
, logs.user_login
, logs.user_event
, logs.datetime_iso8601
, city
, region
, country
, timezone 
,tod_name
,CONVERT_TIMEZONE('UTC',logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME("GAME_EVENT_LTZ") AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ)= tod.hour;
--on hour(logs.datetime_iso8601)= tod.hour;

--on hour(CONVERT_TIMEZONE('UTC'.logs.datetime_iso8601)) = tod.hour;


 --logs.user_login should be renamed to GAMER_NAME
 --logs.user_event should be renamed to GAME_EVENT_NAME
 --logs.datetime_iso8601 should be renamed to GAME_EVENT_UTC
--timezone should be renamed GAMER_LTZ_NAME


---right query below
    SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour;



--Use two functions supplied by IPShare to help with an efficient IP Lookup Process!
--Wrap any Select in a CTAS statement
create or replace table ags_game_audience.enhanced.logs_enhanced as(
    SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
--on hour(logs.datetime_iso8601)= tod.hour
--on hour(CONVERT_TIMEZONE('UTC', GAME_EVENT_LTZ)) = tod.hour
--on hour(GAME_EVENT_utc) = tod.hour
);



select * from ags_game_audience.enhanced.logs_enhanced
where  gamer_name like '%prajina';

--update ags_game_audience.enhanced.logs_enhanced
--set 
--dow_name = 'Sat',
--tod_name = 'Early evening'  
--where gamer_name like '%prajina';


select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
  SELECT
   'DNGW03' as step
   ,( select count(*) 
      from ags_game_audience.enhanced.logs_enhanced
      where dow_name = 'Sat'
      and tod_name = 'Early evening'   
      and gamer_name like '%prajina'
     ) as actual
   ,2 as expected
   ,'Playing the game on a Saturday evening' as description
); 


--so far , we:
--normalized the data from a JSON format into a relational presentation,
--added the local time zone using IP address information 
--calculated a timestamp in each gamer's local time zone.
--added columns that can be used to group gaming events by day of week and/or time of day. 


SELECT 'hello';

create or replace task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED
	warehouse=COMPUTE_WH
	schedule='5 MINUTE'
	as SELECT 'hello';


    --You have to run this grant or you won't be able to test your tasks while in SYSADMIN role
--this is true even if SYSADMIN owns the task!!
--grant execute task on account to role SYSADMIN;

use role accountadmin;

--Now you should be able to run the task, even if your role is set to SYSADMIN
execute task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;

--the SHOW command might come in handy to look at the task 
show tasks in account;

--you can also look at any task more in depth using DESCRIBE
describe task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;


EXECUTE TASK AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;

execute task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;


create or replace task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED
	warehouse=COMPUTE_WH
	schedule='5 MINUTE'
	as 
    INSERT INTO AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED 
    SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
    ;


--make a note of how many rows you have in the table --142 rows
select count(*)
from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;

--Run the task to load more rows
execute task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;

--check to see how many rows were added--still 142
select count(*)
from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;



--first we dump all the rows out of the table
truncate table ags_game_audience.enhanced.LOGS_ENHANCED;

--then we put them all back in
INSERT INTO AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED 
    SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
    ;



--clone the table to save this version as a backup
--since it holds the records from the UPDATED FEED file, we'll name it _UF
create table ags_game_audience.enhanced.LOGS_ENHANCED_UF 
clone ags_game_audience.enhanced.LOGS_ENHANCED;

select * from ags_game_audience.enhanced.LOGS_ENHANCED;




--merge for update
MERGE INTO ENHANCED.LOGS_ENHANCED e
USING RAW.LOGS r
ON r.user_login = e.GAMER_NAME
and r.datetime_iso8601 = e.GAME_EVENT_UTC
and r.user_event = e.GAME_EVENT_NAME
WHEN MATCHED THEN
UPDATE SET IP_ADDRESS = 'Hey I updated matching rows!';


truncate table AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;





--merge for upsert
MERGE INTO ENHANCED.LOGS_ENHANCED e
USING 
(
 SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
) r
ON r.GAMER_NAME = e.GAMER_NAME
and r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
and r. GAME_EVENT_NAME = e.GAME_EVENT_NAME
WHEN NOT MATCHED THEN
INSERT
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME) 
VALUES 
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME)
;



--WHEN MATCHED THEN
--UPDATE
--SET IP_ADDRESS = 'Hey I updated matching rows!'
;



--add task
--merge for upsert
create or replace task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED
	warehouse=COMPUTE_WH
	schedule='5 MINUTE'
	as 
MERGE INTO ENHANCED.LOGS_ENHANCED e
USING 
(
 SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
) r
ON r.GAMER_NAME = e.GAMER_NAME
and r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
and r. GAME_EVENT_NAME = e.GAME_EVENT_NAME
WHEN NOT MATCHED THEN
INSERT
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME) 
VALUES 
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME)
;

--WHEN MATCHED THEN
--UPDATE
--SET IP_ADDRESS = 'Hey I updated matching rows!'
;

EXECUTE TASK AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;

--check to see how many rows were added--still 142?
select count(*)
from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;



-----testing

--Testing cycle for MERGE. Use these commands to make sure the Merge works as expected

--Write down the number of records in your table --426
select * from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;

--Run the Merge a few times. No new rows should be added at this time 
EXECUTE TASK AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;

--Check to see if your row count changed --568
select * from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;

--Insert a test record into your Raw Table 
--You can change the user_event field each time to create "new" records 
--editing the ip_address or datetime_iso8601 can complicate things more than they need to 
--editing the user_login will make it harder to remove the fake records after you finish testing 
INSERT INTO ags_game_audience.raw.game_logs 
select PARSE_JSON('{"datetime_iso8601":"2025-01-01 00:00:00.000", "ip_address":"196.197.196.255", "user_event":"fake event", "user_login":"fake user"}');

--After inserting a new row, run the Merge again 
EXECUTE TASK AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED;

--Check to see if any rows were added --711
select * from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;

--When you are confident your merge is working, you can delete the raw records 
delete from ags_game_audience.raw.game_logs where raw_log like '%fake user%';

--You should also delete the fake rows from the enhanced table
delete from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED
where gamer_name = 'fake user';

--Row count should be back to what it was in the beginning-710
select * from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED; 


select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
SELECT
'DNGW04' as step
 ,( select count(*)/iff (count(*) = 0, 1, count(*))
  from table(ags_game_audience.information_schema.task_history
              (task_name=>'LOAD_LOGS_ENHANCED'))) as actual
 ,1 as expected
 ,'Task exists and has been run at least once' as description 
 ); 


use role accountadmin;

CREATE or replace STAGE AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE 
url = 's3://uni-kishore-pipeline'
;

--alter stage AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE 
--set directory = (enable = true);


list @UNI_KISHORE_PIPELINE;--221 rows

--select * from directory(@UNI_KISHORE_PIPELINE);

--alter stage UNI_KISHORE_PIPELINE refresh;


create or replace table AGS_GAME_AUDIENCE.RAW.PIPELINE_LOGS 
(
RAW_LOG VARIANT
);

COPY INTO AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS 
FROM @UNI_KISHORE_PIPELINE
file_format = (FORMAT_NAME = FF_JSON_LOGS);--221 rows loaded



--run again
COPY INTO AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS 
FROM @UNI_KISHORE_PIPELINE
file_format = (FORMAT_NAME = FF_JSON_LOGS);--1 more row loaded each time becoz of idempotency


select * from AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS ;


create or replace view AGS_GAME_AUDIENCE.raw.PL_LOGS
as
select 
RAW_LOG:user_login::text as USER_LOGIN, 
RAW_LOG:user_event::text as USER_EVENT, 
RAW_LOG:ip_address::text as IP_ADDRESS, 
RAW_LOG:datetime_iso8601::TIMESTAMP_NTZ as datetime_iso8601,
RAW_LOG
from PIPELINE_LOGS ;


SELECT * FROM AGS_GAME_AUDIENCE.raw.PL_LOGS;


--LETS REUSE earlier merge task
--add task
--merge for upsert
create or replace task AGS_GAME_AUDIENCE.RAW.LOAD_PL_LOGS
	warehouse=COMPUTE_WH
	schedule='5 MINUTE'
	as 
MERGE INTO AGS_GAME_AUDIENCE.RAW.PIPELINE_LOGS pl
USING 
(
 SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.PL_LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
) r
ON r.GAMER_NAME = pl.GAMER_NAME
and r.GAME_EVENT_UTC = pl.GAME_EVENT_UTC
and r. GAME_EVENT_NAME = pl.GAME_EVENT_NAME
WHEN NOT MATCHED THEN
INSERT
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME) 
VALUES 
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME)
;


select * from AGS_GAME_AUDIENCE.RAW.PL_LOGS;--2.2k rows


create or replace task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES 
	warehouse=COMPUTE_WH
	schedule='5 MINUTE'
	as 
COPY INTO AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS 
FROM @UNI_KISHORE_PIPELINE
file_format = (FORMAT_NAME = FF_JSON_LOGS);--1 more row loaded each time becoz of idempotency


execute task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES ;


select * from AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS ;--2.3k rows 


execute task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES ;
select * from AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS ;--2.3k--now 2.4k 



truncate table ENHANCED.LOGS_ENHANCED;


--Turning on a task is done with a RESUME command
alter task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES resume;
alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED resume;


--Keep this code handy for shutting down the tasks each day
alter task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES suspend;
alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED suspend;


---checking

--Step 1 - how many files in the bucket?
list @AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE;--245

--Step 2 - number of rows in raw table (should be file count x 10)
select count(*) from AGS_GAME_AUDIENCE.RAW.PIPELINE_LOGS;--2430

--Step 3 - number of rows in raw table (should be file count x 10)
select count(*) from AGS_GAME_AUDIENCE.RAW.PL_LOGS;--2430

--Step 4 - number of rows in enhanced table (should be file count x 10 but fewer rows is okay)
select count(*) from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED;--1846

--qury below very expensive
select 
  loc.country--882
, count(1) log_by_country--360
from AGS_GAME_AUDIENCE.RAW.PL_LOGS pl
left join IPINFO_GEOLOC.demo.location loc on IPINFO_GEOLOC.PUBLIC.TO_int(pl.ip_address) between loc.start_ip_int and loc.end_ip_int
where not exists(select 1 from AGS_GAME_AUDIENCE.enhanced.LOGS_ENHANCED le where le.ip_address = pl.ip_address)
group by 1;


use role accountadmin;
grant EXECUTE MANAGED TASK on account to SYSADMIN;

--switch back to sysadmin
use role sysadmin;

---USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL'


create or replace task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES
USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL'
	schedule='5 MINUTE'
	as COPY INTO AGS_GAME_AUDIENCE.raw.PIPELINE_LOGS 
FROM @UNI_KISHORE_PIPELINE
file_format = (FORMAT_NAME = FF_JSON_LOGS);


create or replace task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED
	USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE = 'XSMALL'
    after AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES
	as 
MERGE INTO ENHANCED.LOGS_ENHANCED e
USING 
(
 SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
) r
ON r.GAMER_NAME = e.GAMER_NAME
and r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
and r. GAME_EVENT_NAME = e.GAME_EVENT_NAME
WHEN NOT MATCHED THEN
INSERT
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME) 
VALUES 
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME)
;

--use role accountadmin;


--Turning on a task is done with a RESUME command

alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED resume;
alter task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES resume;



--Keep this code handy for shutting down the tasks each day
alter task AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES suspend;
alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED suspend;


select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
SELECT
'DNGW05' as step
 ,(
   select max(tally) from (
       select CASE WHEN SCHEDULED_FROM = 'SCHEDULE' 
                         and STATE= 'SUCCEEDED' 
              THEN 1 ELSE 0 END as tally 
   from table(ags_game_audience.information_schema.task_history (task_name=>'GET_NEW_FILES')))
  ) as actual
 ,1 as expected
 ,'Task succeeds from schedule' as description
 ); 



SELECT 
    METADATA$FILENAME as log_file_name --new metadata column
  , METADATA$FILE_ROW_NUMBER as log_file_row_id --new metadata column
  , current_timestamp(0) as load_ltz --new local time of load
  , get($1,'datetime_iso8601')::timestamp_ntz as DATETIME_ISO8601
  , get($1,'user_event')::text as USER_EVENT
  , get($1,'user_login')::text as USER_LOGIN
  , get($1,'ip_address')::text as IP_ADDRESS    
  FROM @AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE
  (file_format => 'ff_json_logs');

list @AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE;  



create or replace table AGS_GAME_AUDIENCE.RAW.ED_PIPELINE_LOGS 
AS
SELECT 
    METADATA$FILENAME as log_file_name --new metadata column
  , METADATA$FILE_ROW_NUMBER as log_file_row_id --new metadata column
  , current_timestamp(0) as load_ltz --new local time of load
  , get($1,'datetime_iso8601')::timestamp_ntz as DATETIME_ISO8601
  , get($1,'user_event')::text as USER_EVENT
  , get($1,'user_login')::text as USER_LOGIN
  , get($1,'ip_address')::text as IP_ADDRESS    
  FROM @AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE
  (file_format => 'ff_json_logs');


  select * from AGS_GAME_AUDIENCE.RAW.ED_PIPELINE_LOGS ;

  --improved steps
  --truncate the table rows that were input during the CTAS
truncate table ED_PIPELINE_LOGS;

--reload the table using your COPY INTO
COPY INTO ED_PIPELINE_LOGS
FROM (
    SELECT 
    METADATA$FILENAME as log_file_name 
  , METADATA$FILE_ROW_NUMBER as log_file_row_id 
  , current_timestamp(0) as load_ltz 
  , get($1,'datetime_iso8601')::timestamp_ntz as DATETIME_ISO8601
  , get($1,'user_event')::text as USER_EVENT
  , get($1,'user_login')::text as USER_LOGIN
  , get($1,'ip_address')::text as IP_ADDRESS    
  FROM @AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE
)
file_format = (format_name = ff_json_logs);





---now lets create our own snowpipe

CREATE OR REPLACE PIPE GET_NEW_FILES
auto_ingest=true
aws_sns_topic='arn:aws:sns:us-west-2:321463406630:dngw_topic'
AS 
COPY INTO ED_PIPELINE_LOGS
FROM (
    SELECT 
    METADATA$FILENAME as log_file_name 
  , METADATA$FILE_ROW_NUMBER as log_file_row_id 
  , current_timestamp(0) as load_ltz 
  , get($1,'datetime_iso8601')::timestamp_ntz as DATETIME_ISO8601
  , get($1,'user_event')::text as USER_EVENT
  , get($1,'user_login')::text as USER_LOGIN
  , get($1,'ip_address')::text as IP_ADDRESS    
  FROM @AGS_GAME_AUDIENCE.RAW.UNI_KISHORE_PIPELINE
)
file_format = (format_name = ff_json_logs);


create or replace task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED
	USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'
    schedule='5 MINUTE'
	--after AGS_GAME_AUDIENCE.RAW.GET_NEW_FILES
    
	as MERGE INTO ENHANCED.LOGS_ENHANCED e
USING 
(
 SELECT 
    logs.ip_address
, logs.user_login as GAMER_NAME
, logs.user_event as GAME_EVENT_NAME
, logs.datetime_iso8601 as GAME_EVENT_UTC
, city
, region
, country
, timezone as GAMER_LTZ_NAME
,tod_name
,CONVERT_TIMEZONE('UTC',timezone,logs.datetime_iso8601) AS GAME_EVENT_LTZ
,DAYNAME(GAME_EVENT_LTZ) AS DOW_NAME
--,DAYNAME(logs.datetime_iso8601) AS DOW_NAME
from AGS_GAME_AUDIENCE.RAW.ED_PIPELINE_LOGS logs
JOIN IPINFO_GEOLOC.demo.location loc 
ON IPINFO_GEOLOC.public.TO_JOIN_KEY(logs.ip_address) = loc.join_key
AND IPINFO_GEOLOC.public.TO_INT(logs.ip_address) 
BETWEEN start_ip_int AND end_ip_int
join ags_game_audience.raw.time_of_day_lu tod 
on hour(GAME_EVENT_LTZ) = tod.hour
) r
ON r.GAMER_NAME = e.GAMER_NAME
and r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
and r. GAME_EVENT_NAME = e.GAME_EVENT_NAME
WHEN NOT MATCHED THEN
INSERT
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME) 
VALUES 
(IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME, GAME_EVENT_UTC, CITY, REGION, COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ, DOW_NAME, TOD_NAME);



alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED resume;

select * from ENHANCED.LOGS_ENHANCED;--3.2k


select * from ED_PIPELINE_LOGS;--2.7k


alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED suspend;


--create a stream that will keep track of changes to the table
create or replace stream ags_game_audience.raw.ed_cdc_stream 
on table AGS_GAME_AUDIENCE.RAW.ED_PIPELINE_LOGS;

--look at the stream you created
show streams;

--check to see if any changes are pending
select system$stream_has_data('ed_cdc_stream');


--query the stream
select * 
from ags_game_audience.raw.ed_cdc_stream; 

--check to see if any changes are pending
select system$stream_has_data('ed_cdc_stream');

--if your stream remains empty for more than 10 minutes, make sure your PIPE is running
select SYSTEM$PIPE_STATUS('GET_NEW_FILES');

--if you need to pause or unpause your pipe
alter pipe GET_NEW_FILES set pipe_execution_paused = true;
--alter pipe GET_NEW_FILES set pipe_execution_paused = false;


----new stream process instead of merge 

--make a note of how many rows are in the stream
select * 
from ags_game_audience.raw.ed_cdc_stream; --30

 
--process the stream by using the rows in a merge 
MERGE INTO AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED e
USING (
        SELECT cdc.ip_address 
        , cdc.user_login as GAMER_NAME
        , cdc.user_event as GAME_EVENT_NAME
        , cdc.datetime_iso8601 as GAME_EVENT_UTC
        , city
        , region
        , country
        , timezone as GAMER_LTZ_NAME
        , CONVERT_TIMEZONE( 'UTC',timezone,cdc.datetime_iso8601) as game_event_ltz
        , DAYNAME(game_event_ltz) as DOW_NAME
        , TOD_NAME
        from ags_game_audience.raw.ed_cdc_stream cdc
        JOIN ipinfo_geoloc.demo.location loc 
        ON ipinfo_geoloc.public.TO_JOIN_KEY(cdc.ip_address) = loc.join_key
        AND ipinfo_geoloc.public.TO_INT(cdc.ip_address) 
        BETWEEN start_ip_int AND end_ip_int
        JOIN AGS_GAME_AUDIENCE.RAW.TIME_OF_DAY_LU tod
        ON HOUR(game_event_ltz) = tod.hour
      ) r
ON r.GAMER_NAME = e.GAMER_NAME
AND r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
AND r.GAME_EVENT_NAME = e.GAME_EVENT_NAME 
WHEN NOT MATCHED THEN 
INSERT (IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME
        , GAME_EVENT_UTC, CITY, REGION
        , COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ
        , DOW_NAME, TOD_NAME)
        VALUES
        (IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME
        , GAME_EVENT_UTC, CITY, REGION
        , COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ
        , DOW_NAME, TOD_NAME);--1
 
--Did all the rows from the stream disappear? 
select * 
from ags_game_audience.raw.ed_cdc_stream; ---0 



--------------------
--turn off the other task (we won't need it anymore)
alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED suspend;

--Create a new task that uses the MERGE you just tested
create or replace task AGS_GAME_AUDIENCE.RAW.CDC_LOAD_LOGS_ENHANCED
	USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'
	SCHEDULE = '5 minutes'
	as 
MERGE INTO AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED e
USING (
        SELECT cdc.ip_address 
        , cdc.user_login as GAMER_NAME
        , cdc.user_event as GAME_EVENT_NAME
        , cdc.datetime_iso8601 as GAME_EVENT_UTC
        , city
        , region
        , country
        , timezone as GAMER_LTZ_NAME
        , CONVERT_TIMEZONE( 'UTC',timezone,cdc.datetime_iso8601) as game_event_ltz
        , DAYNAME(game_event_ltz) as DOW_NAME
        , TOD_NAME
        from ags_game_audience.raw.ed_cdc_stream cdc
        JOIN ipinfo_geoloc.demo.location loc 
        ON ipinfo_geoloc.public.TO_JOIN_KEY(cdc.ip_address) = loc.join_key
        AND ipinfo_geoloc.public.TO_INT(cdc.ip_address) 
        BETWEEN start_ip_int AND end_ip_int
        JOIN AGS_GAME_AUDIENCE.RAW.TIME_OF_DAY_LU tod
        ON HOUR(game_event_ltz) = tod.hour
      ) r
ON r.GAMER_NAME = e.GAMER_NAME
AND r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
AND r.GAME_EVENT_NAME = e.GAME_EVENT_NAME 
WHEN NOT MATCHED THEN 
INSERT (IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME
        , GAME_EVENT_UTC, CITY, REGION
        , COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ
        , DOW_NAME, TOD_NAME)
        VALUES
        (IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME
        , GAME_EVENT_UTC, CITY, REGION
        , COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ
        , DOW_NAME, TOD_NAME);
        
--Resume the task so it is running
alter task AGS_GAME_AUDIENCE.RAW.CDC_LOAD_LOGS_ENHANCED resume;



------add when statement

--------------------
--turn off the other task (we won't need it anymore)
alter task AGS_GAME_AUDIENCE.RAW.LOAD_LOGS_ENHANCED suspend;

truncate table ENHANCED.LOGS_ENHANCED;

select * from ENHANCED.LOGS_ENHANCED;

--Create a new task that uses the MERGE you just tested
create or replace task AGS_GAME_AUDIENCE.RAW.CDC_LOAD_LOGS_ENHANCED
	USER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'
	SCHEDULE = '5 minutes'
    when
    system$stream_has_data('ed_cdc_stream')
	as 
MERGE INTO AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED e
USING (
        SELECT cdc.ip_address 
        , cdc.user_login as GAMER_NAME
        , cdc.user_event as GAME_EVENT_NAME
        , cdc.datetime_iso8601 as GAME_EVENT_UTC
        , city
        , region
        , country
        , timezone as GAMER_LTZ_NAME
        , CONVERT_TIMEZONE( 'UTC',timezone,cdc.datetime_iso8601) as game_event_ltz
        , DAYNAME(game_event_ltz) as DOW_NAME
        , TOD_NAME
        from ags_game_audience.raw.ed_cdc_stream cdc
        JOIN ipinfo_geoloc.demo.location loc 
        ON ipinfo_geoloc.public.TO_JOIN_KEY(cdc.ip_address) = loc.join_key
        AND ipinfo_geoloc.public.TO_INT(cdc.ip_address) 
        BETWEEN start_ip_int AND end_ip_int
        JOIN AGS_GAME_AUDIENCE.RAW.TIME_OF_DAY_LU tod
        ON HOUR(game_event_ltz) = tod.hour
      ) r
ON r.GAMER_NAME = e.GAMER_NAME
AND r.GAME_EVENT_UTC = e.GAME_EVENT_UTC
AND r.GAME_EVENT_NAME = e.GAME_EVENT_NAME 
WHEN NOT MATCHED THEN 
INSERT (IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME
        , GAME_EVENT_UTC, CITY, REGION
        , COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ
        , DOW_NAME, TOD_NAME)
        VALUES
        (IP_ADDRESS, GAMER_NAME, GAME_EVENT_NAME
        , GAME_EVENT_UTC, CITY, REGION
        , COUNTRY, GAMER_LTZ_NAME, GAME_EVENT_LTZ
        , DOW_NAME, TOD_NAME);
        
--Resume the task so it is running
alter task AGS_GAME_AUDIENCE.RAW.CDC_LOAD_LOGS_ENHANCED resume;


select * from ENHANCED.LOGS_ENHANCED;

select * from ED_PIPELINE_LOGS;--2.7k

alter pipe GET_NEW_FILES set pipe_execution_paused = false;


select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
SELECT
'DNGW06' as step
 ,(
   select CASE WHEN pipe_status:executionState::text = 'RUNNING' THEN 1 ELSE 0 END 
   from(
   select parse_json(SYSTEM$PIPE_STATUS( 'ags_game_audience.raw.GET_NEW_FILES' )) as pipe_status)
  ) as actual
 ,1 as expected
 ,'Pipe exists and is RUNNING' as description
 ); 


alter pipe GET_NEW_FILES set pipe_execution_paused = true;


Create SCHEMA AGS_GAME_AUDIENCE.CURATED;


--the List Agg function can put both login and logout into a single column in a single row
-- if we don't have a logout, just one timestamp will appear
select GAMER_NAME
      , listagg(GAME_EVENT_LTZ,' / ') as login_and_logout
from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED 
group by gamer_name;


select GAMER_NAME
       ,game_event_ltz as login 
       ,lead(game_event_ltz) 
                OVER (
                    partition by GAMER_NAME 
                    order by GAME_EVENT_LTZ
                ) as logout
       ,coalesce(datediff('mi', login, logout),0) as game_session_length
from AGS_GAME_AUDIENCE.ENHANCED.LOGS_ENHANCED
order by game_session_length desc;


select GRADER(step, (actual = expected), actual, expected, description) as graded_results from
(
SELECT
'DNGW07' as step
 ,(
   select 1 
  ) as actual
 ,1 as expected
 ,'We hope you learned about dashboards' as description
 );



 alter task AGS_GAME_AUDIENCE.RAW.CDC_LOAD_LOGS_ENHANCED suspend;
